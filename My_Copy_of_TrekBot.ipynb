{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-azra3l/star-trek-chat-bot/blob/main/My_Copy_of_TrekBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TrekBot Colab\n",
        "\n",
        "Install a few necessary packages."
      ],
      "metadata": {
        "id": "WJki-8BTOjQj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDa-3B1j6RXn"
      },
      "outputs": [],
      "source": [
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install scikit-learn\n",
        "!pip install openai\n",
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we import the packages we'll need.\n",
        "\n",
        "\n",
        "**pandas** is a package that allows us to conveniently store and manipulate data in a data structure known as a Dataframe. (This is similar to a Dataframe in R, for those familiar with R.) It’s a very common tool for anyone doing data science in python.\n",
        "\n",
        "**sklearn** is the package formally called “scikit-learn”, and contains a wide range of statistical and machine learning methods. It’s another very common package for data scientists in python.\n",
        "\n",
        "**numpy** is python’s main numeric library, and allows us to do things like work with arrays, matrices, dot products, etc.\n",
        "\n",
        "**json** is a package for interacting with json files. Our data is formatted as a single json file, so this is useful for us here.\n",
        "\n",
        "**os** helps us with file management and command-line commands.\n",
        "\n",
        "**openai** is a package containing functions that allow us to easily make API calls to OpenAI’s models in python.\n",
        "\n",
        "import **cosine_similarity** from sklearn, since it’s a specialized function that we need.\n",
        "\n",
        "import the **dotenv** module and load the environment variables using the **load_dotenv()** function.\n",
        "\n",
        "Finally, we import **google.colab** to have access to google drive"
      ],
      "metadata": {
        "id": "BuN-ORGzYP5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import openai\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import os\n",
        "import dotenv\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load environment variables from the .env file\n",
        "dotenv_path = '/content/drive/MyDrive/Colab Notebooks/.env'  # Replace with the correct path to your .env file\n",
        "dotenv.load_dotenv(dotenv_path)\n",
        "\n",
        "# Define constants\n",
        "CHUNK_SIZE = 600\n",
        "OVERLAP = 20"
      ],
      "metadata": {
        "id": "nv9fSpa1-SmS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1c9149f-705d-44ed-a7b6-552ee57cdb64"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember the OpenAI API key you created? Copy and paste it in in your .env file. API_KEY = your apikey"
      ],
      "metadata": {
        "id": "i73a2SiNYWz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the OpenAI API key from the environment variable\n",
        "openai.api_key = os.getenv('API_KEY')  # Replace 'API_KEY' with the name of your environment variable\n"
      ],
      "metadata": {
        "id": "9YbnFGeS-e5Z"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's what the model is doing: we have a long piece of text that we want ChatGPT to be able to answer questions about. We first break that text up into chunks containing 600 words (technically called “tokens”), where each chunk overlaps 20 words with the following chunk. We then send these chunks to OpenAI to obtain their embeddings. When we ask a question about our text, we find the question’s embedding, and use cosine similarity to find the chunk of text that is closest to our question. We then send a query to ChatGPT that includes our original question, as well as the chunk of text as context.\n",
        "\n",
        "We loop over all the chunks, and send each one to OpenAI, get back the embedding, and then write a new line to the Dataframe df. Note that we are casting the embedding response (a string) to a numpy array. We do this because we will be doing numerical operations on the embedding in just a moment."
      ],
      "metadata": {
        "id": "qq0Z-KFYYbuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the scripts from the JSON file\n",
        "scripts = json.load(open(\"/content/drive/MyDrive/Colab Notebooks/data/all_scripts_raw.json\", encoding='ascii'))  # Replace with your correct path\n",
        "\n",
        "# Prompt the user to enter the text to include for the bot's knowledge\n",
        "text = input(\"Enter the text to include for the bot's knowledge: \")\n",
        "\n",
        "# Split the text into a list of words\n",
        "text_list = text.split()\n",
        "\n",
        "# Divide the text into chunks\n",
        "chunks = [text_list[i:i+CHUNK_SIZE] for i in range(0, len(text_list), CHUNK_SIZE-OVERLAP)]\n",
        "\n",
        "# Create an empty DataFrame to store the chunks, GPT response, and embeddings\n",
        "df = pd.DataFrame(columns=['chunk', 'gpt_raw', 'embedding'])\n",
        "\n",
        "# Process each chunk\n",
        "for chunk in chunks:\n",
        "    # Generate the embedding for the chunk using OpenAI Embedding API\n",
        "    f = openai.Embedding.create(\n",
        "        model=\"text-embedding-ada-002\",\n",
        "        input=\" \".join(chunk),\n",
        "    )\n",
        "\n",
        "    # Store the chunk, GPT response, and embedding in the DataFrame\n",
        "    df.loc[len(df.index)] = (chunk, f, np.array(f['data'][0]['embedding']))"
      ],
      "metadata": {
        "id": "nR3icJ14_Di0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41e19a91-f8ce-4f36-b03d-e190044d553a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the text to include for the bot's knowledge: testing if the code didn't break\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the DataFrame\n",
        "df.head()"
      ],
      "metadata": {
        "id": "fh6mCPlNOtgc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "c8963867-3f98-4dec-fa2f-242f22f848f6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     chunk  \\\n",
              "0  [testing, if, the, code, didn't, break]   \n",
              "\n",
              "                                             gpt_raw  \\\n",
              "0  {'object': 'list', 'data': [{'object': 'embedd...   \n",
              "\n",
              "                                           embedding  \n",
              "0  [3.693080725497566e-05, 0.003650631522759795, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0fa71ea8-8e9c-464f-9423-b7732ef8be52\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chunk</th>\n",
              "      <th>gpt_raw</th>\n",
              "      <th>embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[testing, if, the, code, didn't, break]</td>\n",
              "      <td>{'object': 'list', 'data': [{'object': 'embedd...</td>\n",
              "      <td>[3.693080725497566e-05, 0.003650631522759795, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0fa71ea8-8e9c-464f-9423-b7732ef8be52')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0fa71ea8-8e9c-464f-9423-b7732ef8be52 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0fa71ea8-8e9c-464f-9423-b7732ef8be52');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let’s define our query and get its embedding. We’ll customize the bot to include knowledge about text user provides. We’ll see that with the right chunk of text, identified by cosine similarity, ChatGPT can answer correctly.\n",
        "\n",
        "We calculate the cosine distance from our query to each chunk, and save the chunk that is most similar to a variable called context_chunk.\n",
        "\n",
        "Finally, we assemble the full query, including the chunk we identified, and send it to ChatGPT via the API:"
      ],
      "metadata": {
        "id": "nOYoYbnYY17L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get user input for the query\n",
        "query = input(\"Enter your query: \")\n",
        "\n",
        "# Generate embedding for the query\n",
        "f = openai.Embedding.create(\n",
        "    model=\"text-embedding-ada-002\",\n",
        "    input=query\n",
        ")\n",
        "query_embedding = np.array(f['data'][0]['embedding'])\n",
        "\n",
        "# Calculate similarity scores\n",
        "similarity = []\n",
        "for arr in df['embedding'].values:\n",
        "    similarity.extend(cosine_similarity(query_embedding.reshape(1, -1), arr.reshape(1, -1)))\n",
        "context_chunk = chunks[np.argmax(similarity)]\n",
        "\n",
        "# Prepare query and context for OpenAI completion\n",
        "query_to_send = \"CONTEXT: \" + \" \".join(context_chunk) + \"\\n\\n\" + query\n",
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-003\",\n",
        "  prompt= query_to_send,\n",
        "  max_tokens=100,\n",
        "  temperature=0\n",
        ")"
      ],
      "metadata": {
        "id": "53974KA0_EuM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a50bfd6f-9c50-4893-cf46-b1320c912a62"
      },
      "execution_count": 20,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your query: what did I test?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the query and context sent to the GPT model\n",
        "print(query_to_send)"
      ],
      "metadata": {
        "id": "P_a-RUeMQ53O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76245e82-3142-46e9-8569-8649c855b5ef"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONTEXT: testing if the code didn't break\n",
            "\n",
            "what did I test?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test our bot. Did it get it right? Execute the cell below to find out!"
      ],
      "metadata": {
        "id": "riOblNiGZA5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the generated response from GPT\n",
        "print(response['choices'][0]['text'].strip())"
      ],
      "metadata": {
        "id": "_i9zCaYV_G9k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d1f09e6-f14b-400f-ba79-02ec594025b1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You tested the code to see if it still works correctly after making changes or updates.\n"
          ]
        }
      ]
    }
  ]
}